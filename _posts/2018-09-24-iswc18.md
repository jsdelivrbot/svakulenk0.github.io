---
layout: post
title: "Measuring Semantic Coherence of a Conversation"
tagline: "ISWC 2018"
category: 
tags: []
---
{% include JB/setup %}

*Preprint*: <https://arxiv.org/pdf/1806.06411.pdf>
*Code*: <https://github.com/svakulenk0/semantic_coherence>

Imagine: you sit in a train, in which many different conversations are going on at the same time. A couple next to the window is planning their honey-moon trip; the girls at the table are discussing their homework; a granny is in a call with her great-grandson. You close your eyes and try to recover who is talking to whom by paying attention to the content of the conversations and not to the origin of the sound waves:

- Mhm .. and then we add the two numbers from the Pythagoras’ equation?
- … but I am not quite sure about that hotel you booked on-line… Don’t you think we should stick with the one we found on Airbnb?
- All right, sweetheart, kiss your mum for me! I will be back before the Disney movie starts, I promise.
- I think it is the one we did on the blackboard on Monday or was it the one with Euclidean distance?
- For me both options are really fine as long as it is on Bali.

It is relatively easy to tell the three conversations apart. We hypothesize that this is due to certain semantic relations between utterances from the same dialogue that make it meaningful, or <b>coherent</b>, which brought us to the following set of questions:

    1. What are the relations between the words in a dialogue (or rather the concepts they represent) that make a dialogue semantically coherent, i.e. making sense? and
    2. Can we use available knowledge resources (e.g. a knowledge graph) to tell whether a dialogue makes sense?

The later is particularly important for dialogue systems that need to correctly interpret the dialogue context and produce meaningful responses.


![](/assets/iswc18.png)
<div style="text-align: right"> <i>Illustration by <a href="https://twitter.com/zvisno" target="_blank">zvisno</a>(c)</i> </div>
<br>

To study these two questions we cast semantic coherence measurement task as a classification problem with the learning objective to distinguish real (mostly coherent) dialogues from artificially generated dialogues, which were made incoherent by design. Intuitively, the classifier is trained to assign a higher score to the coherent dialogues and a lower score to the incoherent (corrupted) dialogues, so that the output score reflects the degree of coherence in the dialogue.

We extended the [Ubuntu Dialogue Corpus](https://github.com/rkadlec/ubuntu-ranking-dataset-creator) with generated negative samples to provide an evaluation benchmark for the coherence measurement task. We implement and evaluate three different approaches using this benchmark.
Two of them are based on a neural network classifier (Convolutional Neural Network) using word or, alternatively, Knowledge Graph embeddings; and the other one is using the original Knowledge Graph (Wikidata+DBpedia converted to HDT) to induce and analyse a semantic subgraph representation for each of the dialogues.

In order to align dialogues with the Knowledge Graph (KG) we perform entity recognition using the [DBpedia Spotlight API](https://www.dbpedia-spotlight.org/demo/).
Thus, each dialogue is represented as a sequence of DBpedia entities.
We perform bidirectional top-k shortest path search (<i>k=5</i>) for each of the entities with respect to the set of entities previously mentioned in the same conversation.
This way we reconstruct the semantic graph of the conversation which includes not only the entities explicitly mentioned in the conversation but also the ones that remain implicit but are tightly related to the mentioned entities since they are located on the intersection between them, i.e. constitute, in some sense, a semantic context (or background) in which the conversation evolves and revolves around:


![](/assets/dialogue_graph.png)



## Results


## Conclusions


The paper will be presented in the [International Semantic Web Conference (ISWC’18) on October 10 at 2pm in the Fred Farr Forum room](http://iswc2018.semanticweb.org/sessions/measuring-semantic-coherence-of-a-conversation/)



## Reference

<b>Svitlana Vakulenko</b>, Maarten de Rijke, Michael Cochez, Vadim Savenkov, and Axel Polleres. Measuring semantic coherence of a conversation. In Proceedings of the 17th International Semantic Web Conference (ISWC 2018), Lecture Notes in Computer Science (LNCS), Monterey, CA, October 2018. Springer. to appear.

```
@inproceedings{Vakulenko2018MeasuringSC,
  title={Measuring semantic coherence of a conversation},
  author={Svitlana Vakulenko and Maarten de Rijke and Michael Cochez and Vadim Savenkov and Axel Polleres},
  booktitle={The Semantic Web - {ISWC} 2018 - 17th International Semantic Web Conference, Monterey, California, USA, October 8-12th, 2018, Proceedings},
  year={2018}
}
```


## Acknowledgements

This research is a product of collaboration between the University of Amsterdam (UvA), Fraunhofer Institute in Sankt Augustin and WU Wien. I am grateful to all my co-authors for the valuable inputs, which enabled this publication.

This work was supported by the following projects: EU H2020 programme under the MSCA-RISE agreement 645751 (RISE_BPM), project Open Data for Local Communities funded by the  Austrian Federal Ministry of Transport,  Innovation and  Technology (BMVIT) under the program "ICT of the Future“,  between November 2016 and April 2019. More information <https://iktderzukunft.at/en/>
